{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab2c4917",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01b8748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer, SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fe6782",
   "metadata": {},
   "source": [
    "# Load the datasets and merge them. \n",
    "## Only keep relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee42cf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('reviews.csv')\n",
    "safedf = df\n",
    "df.drop(columns=[\"id\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edcc97e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listings = pd.read_csv('listings.csv')\n",
    "df_listings = df_listings[[\"id\",'number_of_reviews',\n",
    "       'number_of_reviews_ltm', 'number_of_reviews_l30d', 'first_review',\n",
    "       'last_review', 'review_scores_rating', 'review_scores_accuracy',\n",
    "       'review_scores_cleanliness', 'review_scores_checkin',\n",
    "       'review_scores_communication', 'review_scores_location',\n",
    "       'review_scores_value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5eb9224",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df,df_listings,'left',left_on='listing_id',right_on= 'id',copy=False)\n",
    "df.drop(columns=[\"id\"],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45acc00c",
   "metadata": {},
   "source": [
    "## Check for missing values in 'comments' and 'review_scores_rating'. Drop them. Imputing is not reasonable in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7f28061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "listing_id                       0\n",
       "date                             0\n",
       "reviewer_id                      0\n",
       "reviewer_name                    0\n",
       "comments                       437\n",
       "number_of_reviews                0\n",
       "number_of_reviews_ltm            0\n",
       "number_of_reviews_l30d           0\n",
       "first_review                     0\n",
       "last_review                      0\n",
       "review_scores_rating             0\n",
       "review_scores_accuracy         194\n",
       "review_scores_cleanliness      191\n",
       "review_scores_checkin          198\n",
       "review_scores_communication    193\n",
       "review_scores_location         203\n",
       "review_scores_value            204\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "307834ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, subset=[\"comments\"],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7938c94",
   "metadata": {},
   "source": [
    "# Preprocess the comments for the NLP process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5372b7f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hamue\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cd312a",
   "metadata": {},
   "source": [
    "## Transform text into lower case.\n",
    "## Keep only letters and numbers.\n",
    "## Stem the words.\n",
    "## Store the result in a list format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71bffbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = PorterStemmer()    #plug in here any other stemmer or lemmatiser you want to try out\n",
    "\n",
    "\n",
    "def preprocess(raw_text):\n",
    "    \n",
    "    #regular expression keeping only letters \n",
    "    letnum_text =  re.sub(\"[^a-zA-Z0-9\\s]+\", \" \",raw_text )\n",
    "\n",
    "    # convert to lower case and split into words -> convert string into list ( 'hello world' -> ['hello', 'world'])\n",
    "    words = letnum_text.lower().split()\n",
    "\n",
    "    cleaned_words = []\n",
    "    \n",
    "    \n",
    "    # remove stopwords    \n",
    "    \n",
    "    cleaned_words = [w for w in words if not w.lower() in stop_words]\n",
    "    \n",
    "    # stemm or lemmatise words\n",
    "    stemmed_words = []\n",
    "    for word in cleaned_words:\n",
    "        word = lemmatizer.stem(word)   #dont forget to change stem to lemmatize if you are using a lemmatizer\n",
    "        stemmed_words.append(word)\n",
    "    \n",
    "    # converting list back to string\n",
    "    #return \" \".join(stemmed_words)\n",
    "    return stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "317b182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"comments_processed\"] = df.comments.apply(preprocess)\n",
    "comments= df[\"comments_processed\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c6d6ff",
   "metadata": {},
   "source": [
    "## Save the resulting csv to reduce processing time when restarting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4417e899",
   "metadata": {},
   "source": [
    "df.to_csv(\"reviews_processed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce75f241",
   "metadata": {},
   "source": [
    "# NLP modelling: Build the Word2Vec\n",
    "## Save the words and their embeddings to reduce computation time when restarting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b042ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a4c5cc",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "SIZE = 100\n",
    "WINDOW = 5\n",
    "WORKERS = 4\n",
    "MIN_COUNT = 2\n",
    "# train word2vec model\n",
    "model = gensim.models.Word2Vec(sentences=comments, size=SIZE, window=WINDOW, workers=WORKERS, min_count=MIN_COUNT)\n",
    "# vocab size\n",
    "words = list(model.wv.vocab)\n",
    "print ('Vocabulary size: %d' % len(words))\n",
    "\n",
    "\n",
    "# Store just the words + their trained embeddings.\n",
    "\n",
    "word_vectors = model.wv\n",
    "\n",
    "word_vectors.save(\"word2vec.wordvectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4d2e59da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\hamue\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - gensim\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-4.11.0               |   py39hcbf5309_2        16.9 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        16.9 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda              pkgs/main::conda-4.11.0-py39haa95532_0 --> conda-forge::conda-4.11.0-py39hcbf5309_2\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "conda-4.11.0         | 16.9 MB   |            |   0% \n",
      "conda-4.11.0         | 16.9 MB   |            |   0% \n",
      "conda-4.11.0         | 16.9 MB   | #4         |  14% \n",
      "conda-4.11.0         | 16.9 MB   | ##8        |  29% \n",
      "conda-4.11.0         | 16.9 MB   | ####9      |  50% \n",
      "conda-4.11.0         | 16.9 MB   | ######8    |  68% \n",
      "conda-4.11.0         | 16.9 MB   | #########1 |  91% \n",
      "conda-4.11.0         | 16.9 MB   | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf86277",
   "metadata": {},
   "source": [
    "# Load the saved files; csv and Word2Vec dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbb0fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"reviews_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2da78bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load back with memory-mapping = read-only, shared across processes.\n",
    "\n",
    "wv = KeyedVectors.load(\"word2vec.wordvectors\", mmap='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd90aeef",
   "metadata": {},
   "source": [
    "# Data processing pt.2 - Prepare the comments for ML model\n",
    "## Remove words which are not in the Word2Vec dict.\n",
    "## Calculate the mean vector for every comment (Interpretability?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "990f8836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveUnknownWords(text):\n",
    "    \n",
    "    cleaned_text = []\n",
    "    for w in text:\n",
    "        if w in dict.keys(wv.vocab):\n",
    "            cleaned_text.append(w)        \n",
    "    return cleaned_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5afcac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"comments_processed_2\"] = df[\"comments_processed\"].apply(RemoveUnknownWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cc6cac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateMean(text_list):\n",
    "    vec = np.zeros(100).reshape((1, 100))\n",
    "    count = 0    \n",
    "    for word in text_list:\n",
    "        try:\n",
    "            vec += wv[word].reshape((1, 100))\n",
    "            count += 1.\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "        \n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e58a1478",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"comments_vector\"]=df[\"comments_processed_2\"].apply(CalculateMean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c999df1b",
   "metadata": {},
   "source": [
    "## Flatten the lists to avoid nested lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "00fd727b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (56216000) does not match length of index (562160)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21728/1618267438.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"comments_vector\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mval\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"comments_vector\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3610\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3611\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3612\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3614\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3782\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3783\u001b[0m         \"\"\"\n\u001b[1;32m-> 3784\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3786\u001b[0m         if (\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4508\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4509\u001b[1;33m             \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4510\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \"\"\"\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (56216000) does not match length of index (562160)"
     ]
    }
   ],
   "source": [
    "df[\"comments_vector\"] = [val for sublist in df[\"comments_vector\"] for val in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "517a6058",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df.groupby('listing_id')['comments_vector'].apply(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3c7d24be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = pd.merge(df_agg,df_listings[['id','review_scores_rating']],'left',left_on='listing_id',right_on= 'id',copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc64b5c",
   "metadata": {},
   "source": [
    "## Transform the ratings into categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f633cbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound= df_agg[\"review_scores_rating\"].quantile(0.25)\n",
    "upper_bound= df_agg[\"review_scores_rating\"].quantile(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0b9841df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CategorizeRating(rating,lower_bound,upper_bound):\n",
    "    if rating >=upper_bound:\n",
    "        cat = \"good\"\n",
    "    #elif rating >=lower_bound:\n",
    "        #cat = \"medium\"\n",
    "    else:\n",
    "        cat = \"bad\"\n",
    "    return cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea656d9",
   "metadata": {},
   "source": [
    "# ML model: Predict categorical rating based on comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2e3e60e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_agg[\"comments_vector\"].to_list()\n",
    "y = df_agg[\"review_scores_rating\"].apply(lambda x: CategorizeRating(x,lower_bound, upper_bound))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4793d69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7565591397849463"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e7cb02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
